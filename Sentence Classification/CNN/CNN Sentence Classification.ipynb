{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 54321\n",
    "\n",
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified data\\train_5500.label\n",
      "Found and verified data\\TREC_10.label\n"
     ]
    }
   ],
   "source": [
    "url = 'http://cogcomp.org/Data/QA/QC/'\n",
    "dir_name = 'data'\n",
    "\n",
    "def download_data(dir_name, filename, expected_bytes):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  \n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    if not os.path.exists(os.path.join(dir_name,filename)):\n",
    "        filepath, _ = urlretrieve(url + filename, os.path.join(dir_name,filename))\n",
    "    else:\n",
    "        filepath = os.path.join(dir_name, filename)\n",
    "    \n",
    "    statinfo = os.stat(filepath)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified %s' % filepath)\n",
    "    else:\n",
    "        print(statinfo.st_size)\n",
    "        raise Exception(\n",
    "          'Failed to verify ' + filepath + '. Can you get to it with a browser?')\n",
    "        \n",
    "    return filepath\n",
    "\n",
    "train_filename = download_data(dir_name, 'train_5500.label', 335858)\n",
    "test_filename = download_data(dir_name, 'TREC_10.label',23354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_questions has 5452 questions / 5452 labels\n",
      "Some samples\n",
      "\thow did serfdom develop in and then leave russia ? / cat - DESC / sub_cat - manner\n",
      "\twhat films featured the character popeye doyle ? / cat - ENTY / sub_cat - cremat\n",
      "\thow can i find a list of celebrities ' real names ? / cat - DESC / sub_cat - manner\n",
      "\twhat fowl grabs the spotlight after the chinese year of the monkey ? / cat - ENTY / sub_cat - animal\n",
      "\twhat is the full form of .com ? / cat - ABBR / sub_cat - exp\n",
      "\twhat contemptible scoundrel stole the cork from my lunch ? / cat - HUM / sub_cat - ind\n",
      "\twhat team did baseball 's st. louis browns become ? / cat - HUM / sub_cat - gr\n",
      "\twhat is the oldest profession ? / cat - HUM / sub_cat - title\n",
      "\twhat are liver enzymes ? / cat - DESC / sub_cat - def\n",
      "\tname the scar-faced bounty hunter of the old west . / cat - HUM / sub_cat - ind\n",
      "\n",
      "test_questions has 500 questions / 500 labels\n",
      "Some samples\n",
      "\thow far is it from denver to aspen ? / cat - NUM / sub_cat - dist\n",
      "\twhat county is modesto , california in ? / cat - LOC / sub_cat - city\n",
      "\twho was galileo ? / cat - HUM / sub_cat - desc\n",
      "\twhat is an atom ? / cat - DESC / sub_cat - def\n",
      "\twhen did hawaii become a state ? / cat - NUM / sub_cat - date\n",
      "\thow tall is the sears building ? / cat - NUM / sub_cat - dist\n",
      "\tgeorge bush purchased a small interest in which baseball team ? / cat - HUM / sub_cat - gr\n",
      "\twhat is australia 's national flower ? / cat - ENTY / sub_cat - plant\n",
      "\twhy does the moon turn orange ? / cat - DESC / sub_cat - reason\n",
      "\twhat is autism ? / cat - DESC / sub_cat - def\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    '''\n",
    "    Read data from a file with given filename\n",
    "    Returns a list of strings where each string is a lower case word\n",
    "    '''\n",
    "\n",
    "    questions, categories, sub_categories = [], [], []     \n",
    "    \n",
    "    with open(filename,'r',encoding='latin-1') as f:        \n",
    "        # Read each line\n",
    "        for row in f:   \n",
    "            row_str = row.split(\":\")        \n",
    "            cat, sub_cat_and_question = row_str[0], row_str[1]\n",
    "            tokens = sub_cat_and_question.split(' ')\n",
    "            sub_cat, question = tokens[0], ' '.join(tokens[1:])        \n",
    "            \n",
    "            questions.append(question.lower().strip())\n",
    "            categories.append(cat)\n",
    "            sub_categories.append(sub_cat)\n",
    "            \n",
    "\n",
    "    return questions, categories, sub_categories\n",
    "\n",
    "train_questions, train_categories, train_sub_categories = read_data(train_filename)\n",
    "test_questions, test_categories, test_sub_categories = read_data(test_filename)\n",
    "\n",
    "n_samples = 10\n",
    "print(f\"train_questions has {len(train_questions)} questions / {len(train_categories)} labels\")\n",
    "print(\"Some samples\")\n",
    "for question, cat, sub_cat in zip(train_questions[:n_samples], train_categories[:n_samples], train_sub_categories[:n_samples]):    \n",
    "    print(f\"\\t{question} / cat - {cat} / sub_cat - {sub_cat}\")\n",
    "          \n",
    "print(f\"\\ntest_questions has {len(test_questions)} questions / {len(test_categories)} labels\")\n",
    "print(\"Some samples\")\n",
    "for question, cat, sub_cat in zip(test_questions[:n_samples], test_categories[:n_samples], test_sub_categories[:n_samples]):    \n",
    "    print(f\"\\t{question} / cat - {cat} / sub_cat - {sub_cat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>cremat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>DESC</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>ABBR</td>\n",
       "      <td>exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>what contemptible scoundrel stole the cork fro...</td>\n",
       "      <td>HUM</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>what team did baseball 's st. louis browns bec...</td>\n",
       "      <td>HUM</td>\n",
       "      <td>gr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>what is the oldest profession ?</td>\n",
       "      <td>HUM</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>what are liver enzymes ?</td>\n",
       "      <td>DESC</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>name the scar-faced bounty hunter of the old w...</td>\n",
       "      <td>HUM</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question category sub_category\n",
       "0  how did serfdom develop in and then leave russ...     DESC       manner\n",
       "1   what films featured the character popeye doyle ?     ENTY       cremat\n",
       "2  how can i find a list of celebrities ' real na...     DESC       manner\n",
       "3  what fowl grabs the spotlight after the chines...     ENTY       animal\n",
       "4                    what is the full form of .com ?     ABBR          exp\n",
       "5  what contemptible scoundrel stole the cork fro...      HUM          ind\n",
       "6  what team did baseball 's st. louis browns bec...      HUM           gr\n",
       "7                    what is the oldest profession ?      HUM        title\n",
       "8                           what are liver enzymes ?     DESC          def\n",
       "9  name the scar-faced bounty hunter of the old w...      HUM          ind"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define training and testing\n",
    "train_df = pd.DataFrame(\n",
    "    {'question': train_questions, 'category': train_categories, 'sub_category': train_sub_categories}\n",
    ")\n",
    "test_df = pd.DataFrame(\n",
    "    {'question': test_questions, 'category': test_categories, 'sub_category': test_sub_categories}\n",
    ")\n",
    "\n",
    "train_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data for better randomization\n",
    "train_df = train_df.sample(frac=1.0, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>what is an aurora ?</td>\n",
       "      <td>DESC</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>what articles of clothing are tokens in monopo...</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>what causes rust ?</td>\n",
       "      <td>DESC</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>what does an irate car owner call iron oxide ?</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>termeq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>what do we call the imaginary line along the t...</td>\n",
       "      <td>LOC</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>who did bobby fischer beat to win the world ch...</td>\n",
       "      <td>HUM</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>what poet wrote</td>\n",
       "      <td>HUM</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>in order from the top , the four stripes on a ...</td>\n",
       "      <td>ENTY</td>\n",
       "      <td>color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>what is the definition of cecum ?</td>\n",
       "      <td>DESC</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>what chilean president was killed in a 1973 co...</td>\n",
       "      <td>HUM</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5452 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question category sub_category\n",
       "5267                                what is an aurora ?     DESC          def\n",
       "21    what articles of clothing are tokens in monopo...     ENTY        other\n",
       "3258                                 what causes rust ?     DESC       reason\n",
       "1356     what does an irate car owner call iron oxide ?     ENTY       termeq\n",
       "1529  what do we call the imaginary line along the t...      LOC        other\n",
       "...                                                 ...      ...          ...\n",
       "1174  who did bobby fischer beat to win the world ch...      HUM          ind\n",
       "2020                                    what poet wrote      HUM          ind\n",
       "4192  in order from the top , the four stripes on a ...     ENTY        color\n",
       "4746                  what is the definition of cecum ?     DESC          def\n",
       "2641  what chilean president was killed in a 1973 co...      HUM          ind\n",
       "\n",
       "[5452 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label->ID mapping: {'DESC': 0, 'ENTY': 1, 'LOC': 2, 'NUM': 3, 'HUM': 4, 'ABBR': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>what is an aurora ?</td>\n",
       "      <td>0</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>what articles of clothing are tokens in monopo...</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>what causes rust ?</td>\n",
       "      <td>0</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>what does an irate car owner call iron oxide ?</td>\n",
       "      <td>1</td>\n",
       "      <td>termeq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>what do we call the imaginary line along the t...</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>why is hockey so violent ?</td>\n",
       "      <td>0</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>how many characters makes up a word for typing...</td>\n",
       "      <td>3</td>\n",
       "      <td>count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>what peter blatty novel recounts the horrors o...</td>\n",
       "      <td>1</td>\n",
       "      <td>cremat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>what is measured in curies ?</td>\n",
       "      <td>0</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4472</th>\n",
       "      <td>what does seccession mean ?</td>\n",
       "      <td>0</td>\n",
       "      <td>def</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  category sub_category\n",
       "5267                                what is an aurora ?         0          def\n",
       "21    what articles of clothing are tokens in monopo...         1        other\n",
       "3258                                 what causes rust ?         0       reason\n",
       "1356     what does an irate car owner call iron oxide ?         1       termeq\n",
       "1529  what do we call the imaginary line along the t...         2        other\n",
       "3631                         why is hockey so violent ?         0       reason\n",
       "4802  how many characters makes up a word for typing...         3        count\n",
       "2288  what peter blatty novel recounts the horrors o...         1       cremat\n",
       "803                        what is measured in curies ?         0          def\n",
       "4472                        what does seccession mean ?         0          def"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the label to ID mapping\n",
    "unique_cats = train_df[\"category\"].unique()\n",
    "labels_map = dict(zip(unique_cats, np.arange(unique_cats.shape[0])))\n",
    "print(f\"Label->ID mapping: {labels_map}\")\n",
    "\n",
    "n_classes = len(labels_map)\n",
    "\n",
    "# Convert all string labels to IDs\n",
    "train_df[\"category\"] = train_df[\"category\"].map(labels_map)\n",
    "test_df[\"category\"] = test_df[\"category\"].map(labels_map)\n",
    "\n",
    "# View some data\n",
    "train_df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (4906, 3)\n",
      "Valid size: (546, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>where is the official `` zero '' of the sea le...</td>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>what is the name of the song that dracula play...</td>\n",
       "      <td>1</td>\n",
       "      <td>cremat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>who wrote the book , `` song of solomon '' ?</td>\n",
       "      <td>4</td>\n",
       "      <td>ind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>how do doctors diagnose bone cancer ?</td>\n",
       "      <td>0</td>\n",
       "      <td>manner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>which killer whale died at sea world of a fung...</td>\n",
       "      <td>1</td>\n",
       "      <td>animal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  category sub_category\n",
       "4144  where is the official `` zero '' of the sea le...         2        other\n",
       "5036  what is the name of the song that dracula play...         1       cremat\n",
       "2969       who wrote the book , `` song of solomon '' ?         4          ind\n",
       "349               how do doctors diagnose bone cancer ?         0       manner\n",
       "870   which killer whale died at sea world of a fung...         1       animal"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.1)\n",
    "print(f\"Train size: {train_df.shape}\")\n",
    "print(f\"Valid size: {valid_df.shape}\")\n",
    "\n",
    "# Print data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabluary size: 7874\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Define a tokenizer and fit on train data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df[\"question\"].tolist())\n",
    "\n",
    "# Derive the vocabulary size\n",
    "n_vocab = len(tokenizer.index_word) + 1\n",
    "print(f\"Vocabluary size: {n_vocab}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4906.000000\n",
       "mean       10.044435\n",
       "std         3.764644\n",
       "min         2.000000\n",
       "1%          4.000000\n",
       "50%         9.000000\n",
       "99%        21.000000\n",
       "max        37.000000\n",
       "Name: question, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split each string by \" \", compute length of the list, get the percentiles\n",
    "train_df[\"question\"].str.split(\" \").str.len().describe(percentiles=[0.01, 0.5, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each list of tokens to a list of IDs, using tokenizer's mapping\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df[\"question\"].tolist())\n",
    "train_labels = train_df[\"category\"].values\n",
    "valid_sequences = tokenizer.texts_to_sequences(valid_df[\"question\"].tolist())\n",
    "valid_labels = valid_df[\"category\"].values\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df[\"question\"].tolist())\n",
    "test_labels = test_df[\"category\"].values\n",
    "\n",
    "max_seq_length = 22\n",
    "\n",
    "# Pad shorter sentences and truncate longer ones (maximum length: max_seq_length)\n",
    "preprocessed_train_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    train_sequences, maxlen=max_seq_length, padding='post', truncating='post'\n",
    ")\n",
    "preprocessed_valid_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    valid_sequences, maxlen=max_seq_length, padding='post', truncating='post'\n",
    ")\n",
    "preprocessed_test_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    test_sequences, maxlen=max_seq_length, padding='post', truncating='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ppawa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">503,936</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">19,300</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,100</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │    \u001b[38;5;34m503,936\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │     \u001b[38;5;34m19,300\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │     \u001b[38;5;34m25,700\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │     \u001b[38;5;34m32,100\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m300\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │      \u001b[38;5;34m1,806\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">582,842</span> (2.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m582,842\u001b[0m (2.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">582,842</span> (2.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m582,842\u001b[0m (2.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# Input layer takes word IDs as inputs\n",
    "word_id_inputs = layers.Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "# Get the embeddings of the inputs / out [batch_size, sent_length, output_dim]\n",
    "embedding_out = layers.Embedding(input_dim=n_vocab, output_dim=64)(word_id_inputs)\n",
    "\n",
    "\n",
    "# For all layers: in [batch_size, sent_length, emb_size] / out [batch_size, sent_length, 100]\n",
    "conv1_1 = layers.Conv1D(\n",
    "    100, kernel_size=3, strides=1, padding='same', activation='relu'\n",
    ")(embedding_out)\n",
    "conv1_2 = layers.Conv1D(\n",
    "    100, kernel_size=4, strides=1, padding='same', activation='relu'\n",
    ")(embedding_out)\n",
    "conv1_3 = layers.Conv1D(\n",
    "    100, kernel_size=5, strides=1, padding='same', activation='relu'\n",
    ")(embedding_out)\n",
    "\n",
    "# in previous conve outputs / out [batch_size, sent_length, 300]\n",
    "conv_out = layers.Concatenate(axis=-1)([conv1_1, conv1_2, conv1_3])\n",
    "\n",
    "pool_over_time_out = layers.MaxPool1D(pool_size=max_seq_length, padding='valid')(conv_out)\n",
    "\n",
    "# Flatten the unit length dimension\n",
    "flatten_out = layers.Flatten()(pool_over_time_out)\n",
    "\n",
    "# Compute the final output\n",
    "out = layers.Dense(\n",
    "    n_classes, activation='softmax',\n",
    "    kernel_regularizer=regularizers.l2(0.001)\n",
    ")(flatten_out)\n",
    "\n",
    "# Define the model\n",
    "cnn_model = Model(inputs=word_id_inputs, outputs=out)\n",
    "\n",
    "# Compile the model with loss/optimzier/metrics\n",
    "cnn_model.compile(\n",
    "    loss='sparse_categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.3053 - loss: 1.6922 - val_accuracy: 0.5769 - val_loss: 1.2306 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6546 - loss: 1.0790 - val_accuracy: 0.7179 - val_loss: 0.7977 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8015 - loss: 0.6510 - val_accuracy: 0.7949 - val_loss: 0.5911 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9113 - loss: 0.3692 - val_accuracy: 0.8516 - val_loss: 0.4734 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9604 - loss: 0.2088 - val_accuracy: 0.8700 - val_loss: 0.4190 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9821 - loss: 0.1299 - val_accuracy: 0.8755 - val_loss: 0.4054 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0831 - val_accuracy: 0.8791 - val_loss: 0.4006 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9960 - loss: 0.0661 - val_accuracy: 0.8718 - val_loss: 0.4111 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9985 - loss: 0.0560 - val_accuracy: 0.8755 - val_loss: 0.4192 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m37/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0499\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9992 - loss: 0.0499 - val_accuracy: 0.8755 - val_loss: 0.4251 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9996 - loss: 0.0450 - val_accuracy: 0.8755 - val_loss: 0.4258 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0446 - val_accuracy: 0.8755 - val_loss: 0.4266 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m38/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0438\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0438 - val_accuracy: 0.8755 - val_loss: 0.4270 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0444 - val_accuracy: 0.8755 - val_loss: 0.4271 - learning_rate: 1.0000e-05\n",
      "Epoch 15/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0428 - val_accuracy: 0.8755 - val_loss: 0.4271 - learning_rate: 1.0000e-05\n",
      "Epoch 16/25\n",
      "\u001b[1m36/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0450\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9994 - loss: 0.0450 - val_accuracy: 0.8755 - val_loss: 0.4272 - learning_rate: 1.0000e-05\n",
      "Epoch 17/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9996 - loss: 0.0442 - val_accuracy: 0.8755 - val_loss: 0.4272 - learning_rate: 1.0000e-06\n",
      "Epoch 18/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9998 - loss: 0.0443 - val_accuracy: 0.8755 - val_loss: 0.4272 - learning_rate: 1.0000e-06\n",
      "Epoch 19/25\n",
      "\u001b[1m35/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0445\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9998 - loss: 0.0445 - val_accuracy: 0.8755 - val_loss: 0.4272 - learning_rate: 1.0000e-06\n",
      "Epoch 20/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0444 - val_accuracy: 0.8755 - val_loss: 0.4272 - learning_rate: 1.0000e-06\n",
      "Epoch 21/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9999 - loss: 0.0435 - val_accuracy: 0.8755 - val_loss: 0.4272 - learning_rate: 1.0000e-06\n",
      "Epoch 22/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9994 - loss: 0.0454 - val_accuracy: 0.8755 - val_loss: 0.4273 - learning_rate: 1.0000e-06\n",
      "Epoch 23/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9991 - loss: 0.0442 - val_accuracy: 0.8755 - val_loss: 0.4273 - learning_rate: 1.0000e-06\n",
      "Epoch 24/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0445 - val_accuracy: 0.8755 - val_loss: 0.4273 - learning_rate: 1.0000e-06\n",
      "Epoch 25/25\n",
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0441 - val_accuracy: 0.8755 - val_loss: 0.4273 - learning_rate: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2586978ff80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call backs\n",
    "lr_reduce_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=3, verbose=1,\n",
    "    mode='auto', min_delta=0.0001, min_lr=0.000001\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "cnn_model.fit(\n",
    "    preprocessed_train_sequences, train_labels, \n",
    "    validation_data=(preprocessed_valid_sequences, valid_labels),\n",
    "    batch_size=128, \n",
    "    epochs=25,\n",
    "    callbacks=[lr_reduce_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.3500 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8939999938011169, 'loss': 0.3707362115383148}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(preprocessed_test_sequences, test_labels, return_dict=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
